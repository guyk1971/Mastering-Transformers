{"cells":[{"cell_type":"markdown","metadata":{"id":"blVeQzeMhsUj"},"source":["# CH07c Semantic similarity experiment with FLAIR\n","In this experiment, we will qualitatively evaluate the sentence representation models thanks to the flair library, which really simplifies obtaining the document embeddings for us.\n","\n","We will perform experiments while taking on the following approaches:\n","- Document average pool embeddings\n","- RNN-based embeddings\n","- BERT embeddings\n","- SBERT embeddings\n","\n","\n","For qualitative evaluation, we define a list of similar sentence pairs and a list of dissimilar sentence pairs (five pairs for each). What we expect from the embeddings models is that they should measure a high score and a low score, respectively.  \n","\n","The sentence pairs are extracted from the SBS Benchmark dataset, which we are already familiar with from the sentence-pair regression part of Chapter 6, Fine-Tuning Language Models for Token Classification. For similar pairs, two sentences are completely equivalent, and they share the same meaning."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2880,"status":"ok","timestamp":1625403147126,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"wEY40_YlhrK9","outputId":"e87a3edf-3619-4ea3-f50f-12864134c227"},"outputs":[],"source":["# !pip install flair"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1625403148380,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"SXe1we7j1Pbm"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["The pairs with a similarity score of around 5 in the STSB dataset are randomly taken, as follows:"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1625403150028,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"wGdAEkpOO-hZ","outputId":"83da0fd9-9e68-4f4e-eb7f-42427675fc40"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sen1</th>\n","      <th>sen2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A black dog walking beside a pool.</td>\n","      <td>A black dog is walking along the side of a pool.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A blonde woman looks for medical supplies for ...</td>\n","      <td>The blond woman is searching for medical supp...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A doubly decker red bus driving down the road.</td>\n","      <td>A red double decker bus driving down a street.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>There is a black dog jumping into a swimming p...</td>\n","      <td>A black dog is leaping into a swimming pool.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The man used a sword to slice a plastic bottle.\\t</td>\n","      <td>A man sliced a plastic bottle with a sword.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                sen1  \\\n","0                 A black dog walking beside a pool.   \n","1  A blonde woman looks for medical supplies for ...   \n","2     A doubly decker red bus driving down the road.   \n","3  There is a black dog jumping into a swimming p...   \n","4  The man used a sword to slice a plastic bottle.\\t   \n","\n","                                                sen2  \n","0   A black dog is walking along the side of a pool.  \n","1   The blond woman is searching for medical supp...  \n","2     A red double decker bus driving down a street.  \n","3       A black dog is leaping into a swimming pool.  \n","4        A man sliced a plastic bottle with a sword.  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["similar=[(\"A black dog walking beside a pool.\",\"A black dog is walking along the side of a pool.\"),\n","(\"A blonde woman looks for medical supplies for work in a suitcase.\t\",\" The blond woman is searching for medical supplies in a suitcase.\"),\n","(\"A doubly decker red bus driving down the road.\",\"A red double decker bus driving down a street.\"),\n","(\"There is a black dog jumping into a swimming pool.\",\"A black dog is leaping into a swimming pool.\"),\n","(\"The man used a sword to slice a plastic bottle.\t\",\"A man sliced a plastic bottle with a sword.\")]\n","pd.DataFrame(similar, columns=[\"sen1\", \"sen2\"])\n"]},{"cell_type":"markdown","metadata":{"id":"G4oFOJRt1Uea"},"source":["Here is the list of dissimilar sentences whose similarity scores are around 0, taken from the STS-B dataset:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1625403154599,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"41H-Pr2F1TZJ","outputId":"0ddf88f1-cfa3-4c1e-e053-d3e37f7607bd"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sen1</th>\n","      <th>sen2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A little girl and boy are reading books.</td>\n","      <td>An older child is playing with a doll while ga...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Two horses standing in a field with trees in t...</td>\n","      <td>A black and white bird on a body of water with...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Two people are walking by the ocean.</td>\n","      <td>Two men in fleeces and hats looking at the cam...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A cat is pouncing on a trampoline.</td>\n","      <td>A man is slicing a tomato.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A woman is riding on a horse.</td>\n","      <td>A man is turning over tables in anger.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                sen1  \\\n","0          A little girl and boy are reading books.    \n","1  Two horses standing in a field with trees in t...   \n","2               Two people are walking by the ocean.   \n","3                 A cat is pouncing on a trampoline.   \n","4                      A woman is riding on a horse.   \n","\n","                                                sen2  \n","0  An older child is playing with a doll while ga...  \n","1  A black and white bird on a body of water with...  \n","2  Two men in fleeces and hats looking at the cam...  \n","3                         A man is slicing a tomato.  \n","4             A man is turning over tables in anger.  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# import pandas as pd\n","dissimilar= [(\"A little girl and boy are reading books. \", \"An older child is playing with a doll while gazing out the window.\"),\n","(\"Two horses standing in a field with trees in the background.\", \"A black and white bird on a body of water with grass in the background.\"),\n","(\"Two people are walking by the ocean.\" , \"Two men in fleeces and hats looking at the camera.\"),\n","(\"A cat is pouncing on a trampoline.\",\"A man is slicing a tomato.\"),\n","(\"A woman is riding on a horse.\",\"A man is turning over tables in anger.\")]\n","pd.DataFrame(dissimilar, columns=[\"sen1\", \"sen2\"])"]},{"cell_type":"markdown","metadata":{"id":"YRNFJ2-z1ey9"},"source":["The following `sim()` function computes the cosine similarity between two sentences; that is, s1, s2:"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1625403157282,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"z5GJ6v52jTan"},"outputs":[],"source":["import torch, numpy as np\n","def sim(s1,s2):\n","  # cosine similarity function outputs in the range 0-1\n","  s1=s1.embedding.unsqueeze(0)\n","  s2=s2.embedding.unsqueeze(0)\n","  sim=torch.cosine_similarity(s1,s2).item() \n","  return np.round(sim,2)\n"]},{"cell_type":"markdown","metadata":{},"source":["The document embeddings models that were used in this experiment are all pre-trained models.  \n","We will pass the document embeddings model object and sentence pair list (similar or dissimilar) to the following `evaluate()` function, where, once the model encodes the sentence embeddings, it will compute the similarity score for each pair in the list, along with the list average. The definition of the function is as follows:"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from flair.data import Sentence\n","def evaluate(embeddings, myPairList):\n","  # it evaluates embeddings for a given list of sentence pair\n","  scores=[]\n","  for s1, s2 in myPairList:\n","    s1,s2=Sentence(s1), Sentence(s2)        # tokenization\n","    embeddings.embed(s1)\n","    embeddings.embed(s2)\n","    score=sim(s1,s2)\n","    scores.append(score)\n","  return scores, np.round(np.mean(scores),2)"]},{"cell_type":"markdown","metadata":{"id":"Ibsr4nTen_BR"},"source":["## Document Pool Embedding\n","\n","The Document Pool embeddings (also called Average word embedding) apply mean pooling operation over all word where the average of all word embeddings in a sentence is computed to obtain sentence embedding.  \n","\n","The following execution instantiates a document pool embedding based on GloVe vectors. Note that although we will use only GloVe vectors here, the flair API allows us to use multiple word embeddings. Here is the code definition:"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1312,"status":"ok","timestamp":1625403161823,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"oAIyv95UmL-7"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-08-25 12:01:33,032 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpqh9t2df4\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 160000128/160000128 [00:06<00:00, 25847639.93B/s]"]},{"name":"stdout","output_type":"stream","text":["2022-08-25 12:01:39,627 copying /tmp/tmpqh9t2df4 to cache at /home/guy/.flair/embeddings/glove.gensim.vectors.npy\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["2022-08-25 12:01:39,733 removing temp file /tmp/tmpqh9t2df4\n","2022-08-25 12:01:40,137 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpl2vmsgkd\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 21494764/21494764 [00:01<00:00, 17825818.54B/s]"]},{"name":"stdout","output_type":"stream","text":["2022-08-25 12:01:41,731 copying /tmp/tmpl2vmsgkd to cache at /home/guy/.flair/embeddings/glove.gensim\n","2022-08-25 12:01:41,744 removing temp file /tmp/tmpl2vmsgkd\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from flair.data import Sentence\n","from flair.embeddings import WordEmbeddings, DocumentPoolEmbeddings\n","glove_embedding = WordEmbeddings('glove')\n","glove_pool_embeddings = DocumentPoolEmbeddings([glove_embedding])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1625403164125,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"JWX30eqA2mho","outputId":"9a918726-d02d-4e7c-86a3-b5a24550dada"},"outputs":[{"data":{"text/plain":["([0.97, 0.99, 0.97, 0.99, 0.98], 0.98)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(glove_pool_embeddings, similar)"]},{"cell_type":"markdown","metadata":{},"source":["The results seem to be good since those resulting values are very high, which is what we expect.  \n","However, the model produces high scores such as 0.94 on average for the dissimilar list as well. Our expectation would be less than 0.4. We'll talk about why we got this later in this chapter. Here is the execution"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1625403166680,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"AU-nmO-uS3o0","outputId":"89a23743-1839-4663-9f52-dedf148d3f2a"},"outputs":[{"data":{"text/plain":["([0.94, 0.97, 0.94, 0.92, 0.93], 0.94)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(glove_pool_embeddings, dissimilar)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1625403166681,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"s3XPI1-qS8Ll"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ntpiluQbosoA"},"source":["## RNN-based Document Embeddings"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1625403169747,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"G97IU2bsgW5q"},"outputs":[],"source":["from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n","gru_embeddings = DocumentRNNEmbeddings([glove_embedding])"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1625403169747,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"41VzAdxeWGlk","outputId":"c92f4a24-c0e5-43d8-91e3-7bd40c047e9f"},"outputs":[{"data":{"text/plain":["([0.98, 1.0, 0.94, 1.0, 0.88], 0.96)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(gru_embeddings, similar)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1625403169748,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"-bysX3GOg2nD","outputId":"7e202928-b26e-4adc-a69f-3706fcbc24fd"},"outputs":[{"data":{"text/plain":["([0.86, 1.0, 0.87, 0.83, 0.86], 0.88)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(gru_embeddings, dissimilar)"]},{"cell_type":"markdown","metadata":{},"source":["Likewise, we get a high score for the dissimilar list. This is not what we want from sentence embeddings."]},{"cell_type":"markdown","metadata":{"id":"ARpG-ZKLPRq0"},"source":["## Transformer-based BERT Embeddings"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4771,"status":"ok","timestamp":1625403177175,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"ZbWdvctrPUMi","outputId":"575721f2-b0a5-43df-e279-307d3c00c77a"},"outputs":[],"source":["from flair.embeddings import TransformerDocumentEmbeddings\n","from flair.data import Sentence\n","bert_embeddings = TransformerDocumentEmbeddings('bert-base-uncased')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1625403177176,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"aJDBBDUx46nv","outputId":"0839ae73-8fba-4af0-a48d-fe560c7f158a"},"outputs":[{"data":{"text/plain":["([0.85, 0.9, 0.96, 0.91, 0.89], 0.9)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(bert_embeddings, similar)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1625403177836,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"P8pz5rWNPeIz","outputId":"cc8247ff-63c9-45b7-c165-da93d17b1142"},"outputs":[{"data":{"text/plain":["([0.93, 0.94, 0.86, 0.93, 0.92], 0.92)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(bert_embeddings, dissimilar)"]},{"cell_type":"markdown","metadata":{},"source":["This is worse! The score of the dissimilar list is higher than that of the similar list."]},{"cell_type":"markdown","metadata":{"id":"5ZWU2ci9d5PH"},"source":["## SentenceBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2614,"status":"ok","timestamp":1625403180441,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"hxtPMb5Gf0Co","outputId":"954fc1fa-aec7-44c4-c0ea-1a55c935af86"},"outputs":[],"source":["# !pip install sentence-transformers"]},{"cell_type":"markdown","metadata":{},"source":["As we mentioned previously, Sentence-BERT provides a variety of pre-trained models. We will pick the bert-base-nli-mean-tokens model for evaluation."]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":607,"status":"ok","timestamp":1625403181044,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"e9Bd0pkfd-v2"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09e4b46cf18d4f72b8db2bf130588f4a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"687e4c1d26434bd4baa63e2ad73932e9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acc5da8d9ebe48adb21e7911ce75bb80","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4f2abef7d274d0d8fdcfb0286609adb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"021feb73c9294d9f9737d93aa1849a8a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69961edf73bb442bbaca1f0ec6312941","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"557dc28aa40b453e85919ef330f719eb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"731b699d71124dc49d719ac2e8b154c9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e2ffaeb78e14d74bc8cf345093c7810","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88ddde433b874babb1ed5d02c4548c53","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"921a35d894aa47f6a0d7bf9e317443ee","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/399 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f8b0fb5d2934ab4b84782013564b6d3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a117a99144554391b0625924e975847d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from flair.data import Sentence\n","from flair.embeddings import SentenceTransformerDocumentEmbeddings\n","# init embedding\n","sbert_embeddings = SentenceTransformerDocumentEmbeddings('bert-base-nli-mean-tokens')"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1625403183147,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"Ah_EtHne5b8M","outputId":"753bb5c7-d3a0-4ee8-f84e-1d41aec1a208"},"outputs":[{"data":{"text/plain":["([0.98, 0.95, 0.96, 0.99, 0.98], 0.97)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(sbert_embeddings, similar)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":543,"status":"ok","timestamp":1625403185126,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"JCatiSukeFRj","outputId":"0848d568-26e4-42ce-ee6c-3d64d9919e33"},"outputs":[{"data":{"text/plain":["([0.48, 0.41, 0.19, -0.05, 0.0], 0.21)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(sbert_embeddings, dissimilar)"]},{"cell_type":"markdown","metadata":{},"source":["Well done! The SBERT model produced better results. The model produced a low similarity score for the dissimilar list, which is what we expect."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1625403186977,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"g33DMFPuV3No"},"outputs":[],"source":["# Tricky pairs"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1625403187567,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"8nKc5WZpoiow"},"outputs":[],"source":["tricky_pairs=[(\"An elephant is bigger than a lion\",\"A lion is bigger than an elephant\") ,(\"the cat sat on the mat\",\"the mat sat on the cat\")]"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":627,"status":"ok","timestamp":1625403190138,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"upbn4myNYftm","outputId":"8e298b4d-27aa-4eca-eef3-72f92d7af53e"},"outputs":[{"data":{"text/plain":["([1.0, 1.0], 1.0)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(glove_pool_embeddings, tricky_pairs)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1625403191793,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"FyY82KodYu6c","outputId":"4e961202-3ae2-44ff-c38d-39d154ab782b"},"outputs":[{"data":{"text/plain":["([0.86, 0.59], 0.72)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(gru_embeddings, tricky_pairs)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":488,"status":"ok","timestamp":1625403192742,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"f-vy11RRY4gN","outputId":"09c4c7ea-d8de-4536-dd57-4b2d3f8da770"},"outputs":[{"data":{"text/plain":["([1.0, 0.98], 0.99)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(bert_embeddings, tricky_pairs)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1625403193160,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"GuHYBnHpY6w-","outputId":"d57bf12d-979d-4bb7-a277-419a0f725860"},"outputs":[{"data":{"text/plain":["([0.93, 0.97], 0.95)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(sbert_embeddings, tricky_pairs)"]},{"cell_type":"markdown","metadata":{},"source":["Interesting! The scores are very high since the sentence similarity model works similar to topic detection and measures content similarity. When we look at the sentences, they share the same content, even though they contradict each other. The content is about lion and elephant or cat and mat. Therefore, the models produce a high similarity score. Since the GloVe embedding method pools the average of the words without caring about word order, it measures two sentences as being the same. On the other hand, the GRU model produced lower values as it cares about word order. Surprisingly, even the SBERT model does not produce efficient scores. This may be due to the content similarity-based supervision that's used in the SBERT model."]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1625403195094,"user":{"displayName":"Savas Yıldırım","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64","userId":"10717726124681851716"},"user_tz":-180},"id":"EqwrD7nFFn3b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/guy/anaconda3/envs/mastrans/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2356: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Permise: An elephant is bigger than a lion\n","Hypothesis: A lion is bigger than an elephant\n","Top Class:\n","contradiction\n","Full softmax scores:\n","contradiction 0.9954543\n","neutral 0.00049089367\n","entailment 0.0040547904\n","====================\n","Permise: the cat sat on the mat\n","Hypothesis: the mat sat on the cat\n","Top Class:\n","entailment\n","Full softmax scores:\n","contradiction 0.49365252\n","neutral 0.007260751\n","entailment 0.49908674\n","====================\n"]}],"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","nli_model = AutoModelForSequenceClassification.from_pretrained('joeddav/xlm-roberta-large-xnli')\n","tokenizer = AutoTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')\n","\n","import numpy as np\n","\n","for permise, hypothesis in tricky_pairs:\n","    x = tokenizer.encode(permise,hypothesis,return_tensors='pt',truncation_strategy='only_first')\n","    logits = nli_model(x)[0]\n","    print(f\"Permise: {permise}\")\n","    print(f\"Hypothesis: {hypothesis}\")\n","    print(\"Top Class:\")\n","    print(nli_model.config.id2label[np.argmax(logits[0].detach().numpy()) ])\n","    print(\"Full softmax scores:\")\n","    for i in range(3):\n","        print(nli_model.config.id2label[i],logits.softmax(dim=1)[0][i].detach().numpy())\n","\n","    print(\"=\"*20)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOMchuwzOkIOmSQ6xTF/xi4","collapsed_sections":[],"machine_shape":"hm","name":"CH07c_Semantic_similarity_experiment_with_FLAIR.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('mastrans')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"46ac275f730ac4cd685e340db4d97ebc86af74e2e59cec90e9c32b87f57bddf9"}}},"nbformat":4,"nbformat_minor":0}
